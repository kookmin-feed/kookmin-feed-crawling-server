# 국민대학교 피드 크롤링 서버

이 프로젝트는 국민대학교의 공지사항, RSS 피드, 공모전 정보를 크롤링하여 새로운 공지사항을 확인하고 데이터베이스에 저장하는 서버입니다.

## 주요 기능

- **공지사항 크롤링**: 다양한 소스(예: RSS 피드, 웹사이트)에서 공지사항을 수집합니다.
- **중복 확인**: 기존 데이터와 비교하여 새로운 공지사항만 저장합니다.
- **데이터베이스 관리**: MongoDB를 사용하여 공지사항 데이터를 저장 및 관리합니다.
- **로깅**: 크롤링 및 데이터 처리 과정에서 발생하는 이벤트를 로깅합니다.

## 기술 스택

- **언어**: Python
- **웹 크롤링**: BeautifulSoup, feedparser
- **비동기 처리**: asyncio
- **데이터베이스**: MongoDB
- **로깅**: Python `logging` 모듈
- **환경 변수 관리**: `.env` 파일

## 설치 및 실행

### 1. 의존성 설치

```bash
pip install -r requirements.txt
```

### 2. 환경 변수 설정

`.env` 파일을 생성하고 다음과 같은 환경 변수를 설정하세요:

```
IS_PROD=True
MONGO_URI=mongodb://localhost:27017
```

### 3. 데이터베이스 초기화

스크래퍼 메타데이터를 초기화하려면 다음 명령어를 실행하세요:

```bash
python -m utils.check_new_scraper
```

### 4. 서버 실행

```bash
python main.py
```

## 주요 파일 설명

- **`main.py`**: 서버의 진입점으로, 크롤링 작업을 관리합니다.
- **`utils/web_scraper.py`**: 웹 스크래퍼의 추상 클래스 및 공통 로직을 정의합니다.
- **`web_scraper/rss_notice_scraper.py`**: RSS 피드에서 공지사항을 크롤링하는 클래스입니다.
- **`config/logger_config.py`**: 로깅 설정을 관리합니다.
- **`config/db_config.py`**: MongoDB 연결 및 데이터베이스 작업을 처리합니다.

## 사용법

1. 서버를 실행하면 설정된 간격(`INTERVAL`)으로 크롤링 작업이 수행됩니다.
2. 새로운 공지사항이 발견되면 데이터베이스에 저장됩니다.
3. 로그를 통해 크롤링 상태를 확인할 수 있습니다.

## 개발 및 테스트

- **테스트 환경**: 개발 환경에서는 `INTERVAL`이 짧게 설정되어 빠르게 테스트할 수 있습니다.
- **로깅**: 개발 환경에서는 DEBUG 레벨의 로그를 출력합니다.
