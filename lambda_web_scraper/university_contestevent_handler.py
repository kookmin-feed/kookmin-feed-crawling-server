import json

from datetime import datetime, timedelta
import pytz
import re
from typing import Dict, Any
from common_utils import (
    fetch_page,
    get_recent_notices,
    save_notices_to_db,
    send_slack_notification,
)


def handler(event, context):
    """
    ëŒ€í•™ ê³µëª¨í–‰ì‚¬ê³µì§€ ìŠ¤í¬ë˜í¼ Lambda Handler
    ê¹”ë”í•˜ê³  ë…ë¦½ì ì¸ êµ¬í˜„
    """

    print("ğŸš€ [HANDLER] Lambda Handler ì‹œì‘")

    try:
        # ë™ê¸° ìŠ¤í¬ë˜í¼ ì‹¤í–‰
        result = scrape_university_contestevent()

        return {
            "statusCode": 200,
        }

    except Exception as e:
        error_msg = f"Lambda Handler ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [HANDLER] {error_msg}")
        send_slack_notification(error_msg, "university_contestevent")
        return {
            "statusCode": 500,
        }


def scrape_university_contestevent() -> Dict[str, Any]:
    """
    ëŒ€í•™ ê³µëª¨í–‰ì‚¬ê³µì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ ì²˜ë¦¬
    """

    url = "https://www.kookmin.ac.kr/user/kmuNews/notice/9/index.do"
    kst = pytz.timezone("Asia/Seoul")

    print(f"ğŸŒ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì‹œì‘ - URL: {url}")

    try:
        # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
        soup = fetch_page(url)

        # ê³µì§€ì‚¬í•­ ëª©ë¡ ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
        elements = soup.select("div.board_list > ul > li")
        print(f"ğŸ“Š [SCRAPER] ë°œê²¬ëœ ê³µì§€ì‚¬í•­ ìˆ˜: {len(elements)}")

        # ê¸°ì¡´ ê³µì§€ì‚¬í•­ í™•ì¸ (MongoDBì—ì„œ)
        recent_notices = get_recent_notices("university_contestevent")
        recent_links = {notice.get("link") for notice in recent_notices}
        recent_titles = {notice.get("title") for notice in recent_notices}

        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ íŒŒì‹±
        new_notices = []

        for element in elements:
            notice = parse_notice_from_element(element, kst)
            if notice:
                # 30ì¼ ì´ë‚´ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                thirty_days_ago = datetime.now(kst) - timedelta(days=30)
                published_date = datetime.fromisoformat(
                    notice["published"].replace("Z", "+00:00")
                )
                if published_date >= thirty_days_ago:
                    # ì¤‘ë³µ í™•ì¸
                    if (
                        notice["link"] not in recent_links
                        and notice["title"] not in recent_titles
                    ):
                        new_notices.append(notice)
                        print(
                            f"ğŸ†• [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­: {notice['title'][:30]}..."
                        )
                else:
                    print(
                        f"â° [SCRAPER] 30ì¼ ì´ì „ ê³µì§€ì‚¬í•­ ì œì™¸: {notice['title'][:30]}..."
                    )

        print(f"ğŸ“ˆ [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ ìˆ˜: {len(new_notices)}")

        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ MongoDBì— ì €ì¥
        saved_count = 0
        if new_notices:
            saved_count = save_notices_to_db(new_notices, "university_contestevent")
            print(f"ğŸ’¾ [SCRAPER] ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ")

        result = {
            "success": True,
            "message": f"ëŒ€í•™ ê³µëª¨í–‰ì‚¬ê³µì§€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ",
            "total_found": len(elements),
            "new_notices_count": len(new_notices),
            "saved_count": saved_count,
            "new_notices": new_notices,
        }

        print(f"ğŸ‰ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
        return result

    except Exception as e:
        error_msg = f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [SCRAPER] {error_msg}")
        send_slack_notification(error_msg, "university_contestevent")
        return {"success": False, "error": error_msg}


def parse_notice_from_element(element, kst) -> Dict[str, Any]:
    """HTML ìš”ì†Œì—ì„œ ê³µëª¨í–‰ì‚¬ê³µì§€ ì •ë³´ë¥¼ ì¶”ì¶œ"""

    try:
        base_url = "https://www.kookmin.ac.kr"

        # ê³µì§€ì‚¬í•­ ì—¬ë¶€ í™•ì¸
        is_notice = "notice" in element.get("class", [])

        # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ - ê³µì§€ì‚¬í•­ê³¼ ì¼ë°˜ ê²Œì‹œë¬¼ì˜ êµ¬ì¡°ê°€ ë‹¤ë¦„
        a_tag = element.select_one("a")
        if not a_tag:
            return None

        relative_link = a_tag.get("href", "")
        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if relative_link.startswith("/"):
            link = f"{base_url}{relative_link}"
        else:
            link = relative_link

        # ê³µì§€ì‚¬í•­ê³¼ ì¼ë°˜ ê²Œì‹œë¬¼ì˜ ì œëª© ì¶”ì¶œ ë°©ì‹ì´ ë‹¤ë¦„
        if is_notice:
            # ê³µì§€ì‚¬í•­ì€ p.titleì´ a íƒœê·¸ ë°”ë¡œ ì•„ë˜ì— ìˆìŒ
            title_element = a_tag.select_one("p.title")
        else:
            # ì¼ë°˜ ê²Œì‹œë¬¼ì€ board_txt í´ë˜ìŠ¤ ì•ˆì— p.titleì´ ìˆìŒ
            title_element = a_tag.select_one("div.board_txt p.title")

        if not title_element:
            return None

        title = title_element.get_text(strip=True)

        # ë‚ ì§œ ì¶”ì¶œ - ì¼ë°˜ ê²Œì‹œë¬¼ê³¼ ê³µì§€ì‚¬í•­ ì²˜ë¦¬ ë°©ì‹ì´ ë‹¤ë¦„
        if is_notice:
            # ê³µì§€ì‚¬í•­ì€ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
            published = get_date_from_detail_page(link, kst)
        else:
            # ì¼ë°˜ ê²Œì‹œë¬¼ì€ ëª©ë¡ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            date_element = element.select_one("div.board_etc span:first-child")
            if not date_element:
                # ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜´
                published = get_date_from_detail_page(link, kst)
            else:
                date_str = date_element.get_text(strip=True)
                try:
                    # YYYY.MM.DD í˜•ì‹
                    published = datetime.strptime(date_str, "%Y.%m.%d").replace(
                        tzinfo=kst
                    )
                except ValueError:
                    try:
                        # YYYY-MM-DD í˜•ì‹
                        published = datetime.strptime(date_str, "%Y-%m-%d").replace(
                            tzinfo=kst
                        )
                    except ValueError:
                        # ë‚ ì§œ í˜•ì‹ì´ ë‹¤ë¥¸ ê²½ìš° ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜´
                        published = get_date_from_detail_page(link, kst)

        # ê³µì§€ì‚¬í•­ì¸ ê²½ìš° ì œëª© ì•ì— [ê³µì§€] í‘œì‹œ ì¶”ê°€
        if is_notice and not title.startswith("[ê³µì§€]"):
            title = f"[ê³µì§€] {title}"

        result = {
            "title": title,
            "link": link,
            "published": published.isoformat(),
            "scraper_type": "university_contestevent",
        }

        return result

    except Exception as e:
        print(f"âŒ [PARSE] ê³µì§€ì‚¬í•­ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def get_date_from_detail_page(url: str, kst) -> datetime:
    """ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        soup = fetch_page(url)

        # ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œ ìš”ì†Œ ì°¾ê¸° - view_top > board_etc > ì‘ì„±ì¼ span
        date_element = soup.select_one("div.view_top div.board_etc span:first-child")
        if not date_element:
            print(f"âš ï¸ [DETAIL] ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {url}")
            return datetime.now(kst)

        date_str = date_element.get_text(strip=True)
        # "ì‘ì„±ì¼ 2025.03.07" í˜•ì‹ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ
        date_match = re.search(r"ì‘ì„±ì¼\s+(\d{4}[-\.]\d{1,2}[-\.]\d{1,2})", date_str)
        if date_match:
            date_str = date_match.group(1)
        else:
            # ë‹¤ë¥¸ í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰
            date_match = re.search(r"(\d{4}[-\.]\d{1,2}[-\.]\d{1,2})", date_str)
            if date_match:
                date_str = date_match.group(1)
            else:
                print(f"âš ï¸ [DETAIL] ë‚ ì§œ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŒ: {date_str}")
                return datetime.now(kst)

        try:
            # YYYY.MM.DD í˜•ì‹
            if "." in date_str:
                return datetime.strptime(date_str, "%Y.%m.%d").replace(tzinfo=kst)
            # YYYY-MM-DD í˜•ì‹
            else:
                return datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=kst)
        except ValueError as e:
            print(f"âŒ [DETAIL] ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {date_str}, {e}")
            return datetime.now(kst)
    except Exception as e:
        print(f"âŒ [DETAIL] ìƒì„¸ í˜ì´ì§€ ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {e}")
        return datetime.now(kst)
