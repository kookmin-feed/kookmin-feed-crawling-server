import json
import re
from datetime import datetime, timedelta
import pytz
from typing import Dict, Any
from bs4 import BeautifulSoup
from common_utils import (
    fetch_page,
    get_recent_notices,
    save_notices_to_db,
    send_slack_notification,
)


def handler(event, context):
    """
    ìë™ì°¨Â·ìš´ì†¡ë””ìì¸í•™ê³¼ í•™ì‚¬ê³µì§€ ìŠ¤í¬ë˜í¼ Lambda Handler
    """
    print("ğŸš€ [HANDLER] Lambda Handler ì‹œì‘")
    try:
        # ë™ê¸° ìŠ¤í¬ë˜í¼ ì‹¤í–‰
        result = scrape_design_automotive_academic()
        return {
            "statusCode": 200,
        }
    except Exception as e:
        error_msg = f"Lambda Handler ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [HANDLER] {error_msg}")
        send_slack_notification(error_msg, "design_automotive_academic")
        return {
            "statusCode": 500,
        }


def scrape_design_automotive_academic() -> Dict[str, Any]:
    """
    ìë™ì°¨Â·ìš´ì†¡ë””ìì¸í•™ê³¼ í•™ì‚¬ê³µì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ ì²˜ë¦¬
    """
    url = "https://mobility.kookmin.ac.kr/mobility/etc-board/employment-information.do"
    kst = pytz.timezone("Asia/Seoul")
    print(f"ğŸŒ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì‹œì‘ - URL: {url}")
    try:
        # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
        soup = fetch_page(url)
        # ê³µì§€ì‚¬í•­ ëª©ë¡ ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
        elements = soup.select("tbody tr")
        print(f"ğŸ“Š [SCRAPER] ë°œê²¬ëœ ê³µì§€ì‚¬í•­ ìˆ˜: {len(elements)}")
        # ê¸°ì¡´ ê³µì§€ì‚¬í•­ í™•ì¸ (MongoDBì—ì„œ)
        recent_notices = get_recent_notices("design_automotive_academic")
        recent_links = {notice.get("link") for notice in recent_notices}
        recent_titles = {notice.get("title") for notice in recent_notices}
        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ íŒŒì‹±
        new_notices = []
        for element in elements:
            notice = parse_notice_from_element(element, kst, url)
            if notice:
                # 30ì¼ ì´ë‚´ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                thirty_days_ago = datetime.now(kst) - timedelta(days=30)
                published_date = datetime.fromisoformat(
                    notice["published"].replace("Z", "+00:00")
                )
                if published_date >= thirty_days_ago:
                    # ì¤‘ë³µ í™•ì¸
                    if (
                        notice["link"] not in recent_links
                        and notice["title"] not in recent_titles
                    ):
                        new_notices.append(notice)
                        print(
                            f"ğŸ†• [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­: {notice['title'][:30]}..."
                        )
                else:
                    print(
                        f"â° [SCRAPER] 30ì¼ ì´ì „ ê³µì§€ì‚¬í•­ ì œì™¸: {notice['title'][:30]}..."
                    )
        print(f"ğŸ“ˆ [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ ìˆ˜: {len(new_notices)}")
        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ MongoDBì— ì €ì¥
        saved_count = 0
        if new_notices:
            saved_count = save_notices_to_db(new_notices, "design_automotive_academic")
            print(f"ğŸ’¾ [SCRAPER] ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ")
        result = {
            "success": True,
            "message": f"ìë™ì°¨Â·ìš´ì†¡ë””ìì¸í•™ê³¼ í•™ì‚¬ê³µì§€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ",
            "total_found": len(elements),
            "new_notices_count": len(new_notices),
            "saved_count": saved_count,
            "new_notices": new_notices,
        }
        print(f"ğŸ‰ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
        return result
    except Exception as e:
        error_msg = f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [SCRAPER] {error_msg}")
        send_slack_notification(error_msg, "design_automotive_academic")
        return {"success": False, "error": error_msg}


def parse_notice_from_element(element, kst, base_url) -> Dict[str, Any]:
    """HTML ìš”ì†Œì—ì„œ ìë™ì°¨Â·ìš´ì†¡ë””ìì¸í•™ê³¼ í•™ì‚¬ê³µì§€ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    try:
        # ìƒë‹¨ ê³ ì • ê³µì§€ ì—¬ë¶€ í™•ì¸
        notice_box = element.select_one(".b-num-box")
        is_top_notice = notice_box and "num-notice" in notice_box.get("class", [])
        # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
        title_element = element.select_one(".b-title-box a")
        if not title_element:
            return None
        title = title_element.get_text(strip=True)
        title = re.sub(r"\s+", " ", title).strip()
        title = re.sub(r" ìì„¸íˆ ë³´ê¸°$", "", title)
        # ì˜ë¦° ì œëª© ë³µêµ¬
        if title.endswith("..."):
            full_title = title_element.get("title", "")
            if full_title and "ìì„¸íˆ ë³´ê¸°" in full_title:
                title = re.sub(r" ìì„¸íˆ ë³´ê¸°$", "", full_title)
        # ê³µì§€ í‘œì‹œ ì¶”ê°€
        if is_top_notice and not title.startswith("[ê³µì§€]"):
            title = f"[ê³µì§€] {title}"
        # ë§í¬ ì²˜ë¦¬
        link_href = title_element.get("href", "")
        if link_href.startswith("?"):
            base_url = base_url.split("?")[0]
            link = f"{base_url}{link_href}"
        else:
            link = link_href
        # ë‚ ì§œ ì¶”ì¶œ
        date_element = element.select_one(".b-date")
        if not date_element:
            published = datetime.now(kst)
        else:
            date_text = date_element.text.strip()
            date_match = re.search(r"(\d{2})\.(\d{2})\.(\d{2})", date_text)
            if date_match:
                year, month, day = date_match.groups()
                year = "20" + year
                published = datetime.strptime(
                    f"{year}-{month}-{day}", "%Y-%m-%d"
                ).replace(tzinfo=kst)
            else:
                published = datetime.now(kst)
        result = {
            "title": title,
            "link": link,
            "published": published.isoformat(),
            "scraper_type": "design_automotive_academic",
        }
        return result
    except Exception as e:
        print(f"âŒ [PARSE] ê³µì§€ì‚¬í•­ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None
