from datetime import datetime, timedelta
import pytz
from typing import Dict, Any
import re
import os
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
from common_utils import (
    get_recent_notices,
    save_notices_to_db,
    send_slack_notification,
)


def fetch_page_with_playwright(url: str, timeout: int = 30000) -> BeautifulSoup:
    """Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì  ì½˜í…ì¸ ê°€ ë¡œë“œëœ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ BeautifulSoup ê°ì²´ë¡œ ë°˜í™˜"""

    try:
        print(f"ğŸ” [PLAYWRIGHT] ìš”ì²­ ì‹œì‘: {url}")

        # AWS Lambda í™˜ê²½ ê°ì§€
        is_lambda = bool(os.environ.get("AWS_LAMBDA_FUNCTION_NAME"))

        # Lambda í™˜ê²½ì—ì„œ Playwright ì„¤ì •
        if is_lambda:
            # Lambda í™˜ê²½ì—ì„œëŠ” /tmpì— ë¸Œë¼ìš°ì € ë°”ì´ë„ˆë¦¬ê°€ í•„ìš”
            os.environ["PLAYWRIGHT_BROWSERS_PATH"] = "/opt/playwright"

        with sync_playwright() as p:
            # Lambda í™˜ê²½ì— ë§ëŠ” ë¸Œë¼ìš°ì € ì„¤ì •
            if is_lambda:
                browser = p.chromium.launch(
                    headless=True,
                    args=[
                        "--no-sandbox",
                        "--disable-setuid-sandbox",
                        "--disable-dev-shm-usage",
                        "--disable-accelerated-2d-canvas",
                        "--no-first-run",
                        "--no-zygote",
                        "--single-process",
                        "--disable-gpu",
                        "--disable-background-timer-throttling",
                        "--disable-backgrounding-occluded-windows",
                        "--disable-renderer-backgrounding",
                        "--disable-web-security",
                        "--disable-features=TranslateUI",
                        "--disable-extensions",
                    ],
                )
            else:
                # ë¡œì»¬ í™˜ê²½
                browser = p.chromium.launch(headless=True)

            page = browser.new_page()

            # User-Agent ì„¤ì •
            page.set_extra_http_headers(
                {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                }
            )

            # í˜ì´ì§€ ì´ë™ ë° ë¡œë”© ëŒ€ê¸°
            page.goto(url, timeout=timeout)

            # Angular ì»´í¬ë„ŒíŠ¸ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            # ê³µì§€ì‚¬í•­ í…Œì´ë¸”ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
            try:
                page.wait_for_selector("table.ikc-bulletins", timeout=10000)
                print("âœ… [PLAYWRIGHT] í…Œì´ë¸” ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ [PLAYWRIGHT] í…Œì´ë¸” ë¡œë”© ëŒ€ê¸° ì‹¤íŒ¨: {e}")
                # í…Œì´ë¸”ì´ ì—†ì–´ë„ í˜ì´ì§€ ì½˜í…ì¸ ëŠ” ê°€ì ¸ì™€ ë´„

            # ì¶”ê°€ì ìœ¼ë¡œ ì¡°ê¸ˆ ë” ëŒ€ê¸° (ë™ì  ì½˜í…ì¸  ì™„ì „ ë¡œë”©)
            page.wait_for_timeout(2000)

            # HTML ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
            html_content = page.content()
            browser.close()

            print(f"âœ… [PLAYWRIGHT] ì„±ê³µ: {url}")

            # BeautifulSoup ê°ì²´ë¡œ íŒŒì‹±
            soup = BeautifulSoup(html_content, "html.parser")
            return soup

    except Exception as e:
        error_msg = f"Playwright í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [PLAYWRIGHT] {error_msg}")
        raise Exception(error_msg)


def handler(event, context):
    """
    ì„±ê³¡ë„ì„œê´€ ì¼ë°˜ê³µì§€ ìŠ¤í¬ë˜í¼ Lambda Handler
    """

    print("ğŸš€ [HANDLER] Lambda Handler ì‹œì‘ - ì„±ê³¡ë„ì„œê´€ ì¼ë°˜ê³µì§€")

    try:
        # ë™ê¸° ìŠ¤í¬ë˜í¼ ì‹¤í–‰
        result = scrape_library_general()

        return {
            "statusCode": 200,
        }

    except Exception as e:
        error_msg = f"Lambda Handler ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [HANDLER] {error_msg}")
        send_slack_notification(error_msg, "library_general")
        return {
            "statusCode": 500,
        }


def scrape_library_general() -> Dict[str, Any]:
    """
    ì„±ê³¡ë„ì„œê´€ ì¼ë°˜ê³µì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ ì²˜ë¦¬
    """

    url = "https://lib.kookmin.ac.kr/library-guide/notice"
    kst = pytz.timezone("Asia/Seoul")

    print(f"ğŸŒ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì‹œì‘ - URL: {url}")

    try:
        # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° (Playwright ì‚¬ìš©)
        soup = fetch_page_with_playwright(url)

        # ê³µì§€ì‚¬í•­ ëª©ë¡ ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
        elements = soup.select("table.ikc-bulletins tbody tr.ng-star-inserted")
        print(f"ğŸ“Š [SCRAPER] ë°œê²¬ëœ ê³µì§€ì‚¬í•­ ìˆ˜: {len(elements)}")

        # ê¸°ì¡´ ê³µì§€ì‚¬í•­ í™•ì¸ (MongoDBì—ì„œ)
        recent_notices = get_recent_notices("library_general")
        recent_links = {notice.get("link") for notice in recent_notices}
        recent_titles = {notice.get("title") for notice in recent_notices}

        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ íŒŒì‹±
        new_notices = []

        for element in elements:
            notice = parse_notice_from_element(element, kst)
            if notice:
                # 30ì¼ ì´ë‚´ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                thirty_days_ago = datetime.now(kst) - timedelta(days=30)
                published_date = datetime.fromisoformat(
                    notice["published"].replace("Z", "+00:00")
                )
                if published_date >= thirty_days_ago:
                    # ì¤‘ë³µ í™•ì¸
                    if (
                        notice["link"] not in recent_links
                        and notice["title"] not in recent_titles
                    ):
                        new_notices.append(notice)
                        print(
                            f"ğŸ†• [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­: {notice['title'][:30]}..."
                        )
                else:
                    print(
                        f"â° [SCRAPER] 30ì¼ ì´ì „ ê³µì§€ì‚¬í•­ ì œì™¸: {notice['title'][:30]}..."
                    )

        print(f"ğŸ“ˆ [SCRAPER] ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ ìˆ˜: {len(new_notices)}")

        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ MongoDBì— ì €ì¥
        saved_count = 0
        if new_notices:
            saved_count = save_notices_to_db(new_notices, "library_general")
            print(f"ğŸ’¾ [SCRAPER] ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ")

        result = {
            "success": True,
            "message": f"ì„±ê³¡ë„ì„œê´€ ì¼ë°˜ê³µì§€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ",
            "total_found": len(elements),
            "new_notices_count": len(new_notices),
            "saved_count": saved_count,
            "new_notices": new_notices,
        }

        print(f"ğŸ‰ [SCRAPER] ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
        return result

    except Exception as e:
        error_msg = f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ [SCRAPER] {error_msg}")
        send_slack_notification(error_msg, "library_general")
        return {"success": False, "error": error_msg}


def parse_notice_from_element(row, kst) -> Dict[str, Any]:
    """HTML ìš”ì†Œì—ì„œ ì„±ê³¡ë„ì„œê´€ ê³µì§€ ì •ë³´ë¥¼ ì¶”ì¶œ"""

    try:
        # ìˆœë²ˆ ì¶”ì¶œ
        index_element = row.select_one(".ikc-bulletins-index span")
        if not index_element:
            return None

        notice_index = index_element.text.strip()

        # ì œëª© ì¶”ì¶œ
        title_element = row.select_one(".ikc-bulletins-title span")
        if not title_element:
            return None

        title = title_element.text.strip()

        # ë§í¬ ìƒì„± (ìƒì„¸ í˜ì´ì§€ ë§í¬ê°€ ì—†ìœ¼ë¯€ë¡œ ë©”ì¸ í˜ì´ì§€ + ìˆœë²ˆìœ¼ë¡œ êµ¬ì„±)
        base_url = "https://lib.kookmin.ac.kr/library-guide/notice"
        link = f"{base_url}#{notice_index}"

        # ë‚ ì§œ ì¶”ì¶œ - ì‘ì„±ì ì •ë³´ì—ì„œ ë‚ ì§œ ë¶€ë¶„ ì°¾ê¸°
        date_elements = row.select(".ikc-bulletins-properties li span")
        date_str = None

        # date_elements: [ì‘ì„±ì, ë‚ ì§œ, ì¡°íšŒìˆ˜] í˜•íƒœ
        if len(date_elements) >= 2:
            date_text = date_elements[1].text.strip()

            # "Nì›” Nì¼" íŒ¨í„´ í™•ì¸
            if re.match(r"\d{1,2}ì›”\s+\d{1,2}ì¼", date_text):
                # "Nì›” Nì¼" í˜•ì‹ì„ í˜„ì¬ ì—°ë„ì™€ ê²°í•©
                month_day = date_text.replace("ì›”", "").replace("ì¼", "").strip()
                try:
                    month, day = month_day.split()
                    current_year = datetime.now(kst).year
                    date_str = f"{current_year}-{int(month):02d}-{int(day):02d}"
                except ValueError:
                    print(f"âŒ [PARSE] ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_text}")
                    date_str = datetime.now(kst).strftime("%Y-%m-%d")
            # "ì˜¤ì „/ì˜¤í›„ ì‹œ:ë¶„" íŒ¨í„´ë„ í™•ì¸ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
            elif re.match(r"(ì˜¤ì „|ì˜¤í›„)\s+\d{1,2}:\d{2}", date_text):
                # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •
                date_str = datetime.now(kst).strftime("%Y-%m-%d")
            else:
                print(f"âš ï¸ [PARSE] ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ í˜•ì‹: {date_text}")
                date_str = datetime.now(kst).strftime("%Y-%m-%d")
        else:
            print(f"âš ï¸ [PARSE] ë‚ ì§œ ìš”ì†Œ ë¶€ì¡±: {len(date_elements)}ê°œ")
            date_str = datetime.now(kst).strftime("%Y-%m-%d")

        published = datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=kst)

        result = {
            "title": title,
            "link": link,
            "published": published.isoformat(),
            "scraper_type": "library_general",
        }

        return result

    except Exception as e:
        print(f"âŒ [PARSE] ê³µì§€ì‚¬í•­ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None
