import json
import re
from datetime import datetime, timedelta
import pytz
from typing import Dict, Any
from bs4 import BeautifulSoup
from common_utils import (
    fetch_page,
    get_recent_notices,
    save_notices_to_db,
    send_slack_notification,
)

def handler(event, context):
    """
    κ³µμ—…λ””μμΈν•™κ³Ό ν•™μ‚¬κ³µμ§€ μ¤ν¬λνΌ Lambda Handler
    κΉ”λ”ν•κ³  λ…λ¦½μ μΈ κµ¬ν„
    """
    print("π€ [HANDLER] Lambda Handler μ‹μ‘")
    try:
        # λ™κΈ° μ¤ν¬λνΌ μ‹¤ν–‰
        result = scrape_design_industrial_academic()
        return {
            "statusCode": 200,
        }
    except Exception as e:
        error_msg = f"Lambda Handler μ‹¤ν–‰ μ¤‘ μ¤λ¥: {str(e)}"
        print(f"β [HANDLER] {error_msg}")
        send_slack_notification(error_msg, "design_industrial_academic")
        return {
            "statusCode": 500,
        }

def scrape_design_industrial_academic() -> Dict[str, Any]:
    """
    κ³µμ—…λ””μμΈν•™κ³Ό ν•™μ‚¬κ³µμ§€λ¥Ό μ¤ν¬λν•‘ν•κ³  μƒλ΅μ΄ κ³µμ§€μ‚¬ν•­μ„ μ²λ¦¬
    """
    url = "https://id.kookmin.ac.kr/id/intro/notice.do"
    kst = pytz.timezone("Asia/Seoul")
    print(f"π [SCRAPER] μ¤ν¬λν•‘ μ‹μ‘ - URL: {url}")
    try:
        # μ›Ήνμ΄μ§€ κ°€μ Έμ¤κΈ°
        soup = fetch_page(url)
        # κ³µμ§€μ‚¬ν•­ λ©λ΅ μ”μ†λ“¤ κ°€μ Έμ¤κΈ°
        elements = soup.select("table.board-table tbody tr")
        print(f"π“ [SCRAPER] λ°κ²¬λ κ³µμ§€μ‚¬ν•­ μ: {len(elements)}")
        # κΈ°μ΅΄ κ³µμ§€μ‚¬ν•­ ν™•μΈ (MongoDBμ—μ„)
        recent_notices = get_recent_notices("design_industrial_academic")
        recent_links = {notice.get("link") for notice in recent_notices}
        recent_titles = {notice.get("title") for notice in recent_notices}
        # μƒλ΅μ΄ κ³µμ§€μ‚¬ν•­ νμ‹±
        new_notices = []
        for element in elements:
            notice = parse_notice_from_element(element, kst, url)
            if notice:
                # 30μΌ μ΄λ‚΄μ λ°μ΄ν„°λ§ ν•„ν„°λ§
                thirty_days_ago = datetime.now(kst) - timedelta(days=30)
                published_date = datetime.fromisoformat(
                    notice["published"].replace("Z", "+00:00")
                )
                if published_date >= thirty_days_ago:
                    # μ¤‘λ³µ ν™•μΈ
                    if (
                        notice["link"] not in recent_links
                        and notice["title"] not in recent_titles
                    ):
                        new_notices.append(notice)
                        print(f"π†• [SCRAPER] μƒλ΅μ΄ κ³µμ§€μ‚¬ν•­: {notice['title'][:30]}...")
                else:
                    print(f"β° [SCRAPER] 30μΌ μ΄μ „ κ³µμ§€μ‚¬ν•­ μ μ™Έ: {notice['title'][:30]}...")
        print(f"π“ [SCRAPER] μƒλ΅μ΄ κ³µμ§€μ‚¬ν•­ μ: {len(new_notices)}")
        # μƒλ΅μ΄ κ³µμ§€μ‚¬ν•­μ„ MongoDBμ— μ €μ¥
        saved_count = 0
        if new_notices:
            saved_count = save_notices_to_db(new_notices, "design_industrial_academic")
            print(f"π’Ύ [SCRAPER] μ €μ¥ μ™„λ£: {saved_count}κ°")
        result = {
            "success": True,
            "message": f"κ³µμ—…λ””μμΈν•™κ³Ό ν•™μ‚¬κ³µμ§€ μ¤ν¬λν•‘ μ™„λ£",
            "total_found": len(elements),
            "new_notices_count": len(new_notices),
            "saved_count": saved_count,
            "new_notices": new_notices,
        }
        print(f"π‰ [SCRAPER] μ¤ν¬λν•‘ μ™„λ£")
        return result
    except Exception as e:
        error_msg = f"μ¤ν¬λν•‘ μ¤‘ μ¤λ¥: {str(e)}"
        print(f"β [SCRAPER] {error_msg}")
        send_slack_notification(error_msg, "design_industrial_academic")
        return {"success": False, "error": error_msg}

def parse_notice_from_element(element, kst, base_url) -> Dict[str, Any]:
    """HTML μ”μ†μ—μ„ κ³µμ—…λ””μμΈν•™κ³Ό ν•™μ‚¬κ³µμ§€ μ •λ³΄λ¥Ό μ¶”μ¶"""
    try:
        # κ³µμ§€μ‚¬ν•­ μ—¬λ¶€ ν™•μΈ
        is_notice = element.select_one(".num-notice") is not None
        # μ λ©κ³Ό λ§ν¬ μ¶”μ¶
        title_element = element.select_one(".b-title-box a")
        if not title_element:
            return None
        title = title_element.get_text(strip=True)
        relative_link = title_element.get("href", "")
        # μƒλ€ κ²½λ΅λ¥Ό μ λ€ κ²½λ΅λ΅ λ³€ν™
        if relative_link.startswith("?"):
            link = f"https://id.kookmin.ac.kr/id/intro/notice.do{relative_link}"
        else:
            link = relative_link
        # λ‚ μ§ μ¶”μ¶ (ε€’μ λ‘ λ²μ§Έ td)
        tds = element.select("td")
        if not tds or len(tds) < 2:
            return None
        date_str = tds[-2].get_text(strip=True)
        try:
            published = datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=kst)
        except ValueError:
            try:
                published = datetime.strptime(date_str, "%Y.%m.%d").replace(tzinfo=kst)
            except ValueError:
                published = datetime.strptime(date_str, "%y.%m.%d").replace(tzinfo=kst)
        result = {
            "title": title,
            "link": link,
            "published": published.isoformat(),
            "scraper_type": "design_industrial_academic",
        }
        return result
    except Exception as e:
        print(f"β [PARSE] κ³µμ§€μ‚¬ν•­ νμ‹± μ¤‘ μ¤λ¥: {e}")
        return None
