import json
import boto3
import os
from pymongo import MongoClient


def handler(event, context):
    """
    Master Lambda Handler
    EventBridgeì—ì„œ í˜¸ì¶œë˜ì–´ ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ Lambda í•¨ìˆ˜ë“¤ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ëŠ” ì§„ì…ì 
    """

    try:
        print("ğŸš€ [MASTER] Master Handler ì‹œì‘")

        # 1. JSON íŒŒì¼ë“¤ ë¡œë“œ
        print("ğŸ“‹ [MASTER] ìŠ¤í¬ë˜í¼ ì„¤ì • íŒŒì¼ ë¡œë“œ")
        scraper_types = load_scraper_types()
        scraper_categories = load_scraper_categories()

        if not scraper_types or not scraper_categories:
            print("âŒ [MASTER] ìŠ¤í¬ë˜í¼ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
            return {
                "statusCode": 500,
                "body": json.dumps(
                    {"error": "ìŠ¤í¬ë˜í¼ ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                    ensure_ascii=False,
                ),
            }

        print(f"ğŸ“Š [MASTER] ë¡œë“œëœ ìŠ¤í¬ë˜í¼ íƒ€ì…: {len(scraper_types)}ê°œ")
        print(f"ğŸ“Š [MASTER] ë¡œë“œëœ ìŠ¤í¬ë˜í¼ ì¹´í…Œê³ ë¦¬: {len(scraper_categories)}ê°œ")

        # 2. Lambda í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        lambda_client = boto3.client("lambda")

        # 3. ëª¨ë“  Lambda í•¨ìˆ˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        print("ğŸ” [MASTER] Lambda í•¨ìˆ˜ ëª©ë¡ ì¡°íšŒ")
        response = lambda_client.list_functions()
        all_functions = response["Functions"]

        # ì¶”ê°€ í˜ì´ì§€ê°€ ìˆëŠ” ê²½ìš° ê³„ì† ê°€ì ¸ì˜¤ê¸°
        while "NextMarker" in response:
            response = lambda_client.list_functions(Marker=response["NextMarker"])
            all_functions.extend(response["Functions"])

        # 4. scraperë¡œ ëë‚˜ëŠ” í•¨ìˆ˜ë“¤ë§Œ í•„í„°ë§
        scraper_functions = [
            func["FunctionName"]
            for func in all_functions
            if func["FunctionName"].endswith("scraper")
        ]

        print(f"ğŸ“‹ [MASTER] ë°œê²¬ëœ ìŠ¤í¬ë˜í¼ Lambda í•¨ìˆ˜: {len(scraper_functions)}ê°œ")

        # 5. ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ í•¨ìˆ˜ë“¤ í•„í„°ë§
        valid_scrapers = validate_scrapers(
            scraper_functions, scraper_types, scraper_categories
        )

        print(f"âœ… [MASTER] ìœ íš¨í•œ ìŠ¤í¬ë˜í¼: {len(valid_scrapers)}ê°œ")
        print(
            f"âŒ [MASTER] ìœ íš¨í•˜ì§€ ì•Šì€ ìŠ¤í¬ë˜í¼: {len(scraper_functions) - len(valid_scrapers)}ê°œ"
        )

        # 6. ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ ì •ë³´ë¥¼ DBì— ì €ì¥
        print("ğŸ’¾ [MASTER] ìŠ¤í¬ë˜í¼ ë©”íƒ€ë°ì´í„° DB ì €ì¥ ì‹œì‘")
        save_scraper_categories_to_db(scraper_categories)
        save_scraper_types_to_db(scraper_types, valid_scrapers)
        print("ğŸ’¾ [MASTER] ìŠ¤í¬ë˜í¼ ë©”íƒ€ë°ì´í„° DB ì €ì¥ ì™„ë£Œ")

        success_count = 0
        error_count = 0
        invocation_results = []

        # 6. ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ í•¨ìˆ˜ë“¤ë§Œ ë¹„ë™ê¸°ë¡œ í˜¸ì¶œ
        for function_name in valid_scrapers:
            try:
                # ê°œë³„ ìŠ¤í¬ë˜í¼ Lambda í•¨ìˆ˜ ë¹„ë™ê¸° í˜¸ì¶œ
                lambda_client.invoke(
                    FunctionName=function_name,
                    InvocationType="Event",  # ë¹„ë™ê¸° í˜¸ì¶œ
                    Payload=json.dumps({}),
                )

                success_count += 1
                invocation_results.append(
                    {
                        "function_name": function_name,
                        "status": "success",
                        "message": "ë¹„ë™ê¸° í˜¸ì¶œ ì„±ê³µ",
                    }
                )

            except Exception as e:
                error_count += 1
                invocation_results.append(
                    {
                        "function_name": function_name,
                        "status": "error",
                        "message": str(e),
                    }
                )

        result = {
            "message": "Master Lambda Handler ì‹¤í–‰ ì™„ë£Œ",
            "validation": {
                "total_found": len(scraper_functions),
                "valid_scrapers": len(valid_scrapers),
                "invalid_scrapers": len(scraper_functions) - len(valid_scrapers),
                "valid_scraper_functions": valid_scrapers,
            },
            "invocation": {
                "total_scrapers": len(valid_scrapers),
                "invoked_successfully": success_count,
                "invocation_failed": error_count,
                "invocation_results": invocation_results,
            },
        }

        print(f"ğŸ‰ [MASTER] ì‹¤í–‰ ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
        return {
            "statusCode": 200,
            "body": json.dumps(result, ensure_ascii=False, default=str),
        }

    except Exception as e:
        print(f"âŒ [MASTER] Master Handler ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "statusCode": 500,
            "body": json.dumps(
                {
                    "error": "Master Lambda Handler ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "details": str(e),
                },
                ensure_ascii=False,
            ),
        }


def load_scraper_types():
    """ìŠ¤í¬ë˜í¼ íƒ€ì… JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("metadata/scraper_types.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("scraper_types", {})
    except Exception as e:
        print(f"âŒ [LOAD] ìŠ¤í¬ë˜í¼ íƒ€ì… íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def load_scraper_categories():
    """ìŠ¤í¬ë˜í¼ ì¹´í…Œê³ ë¦¬ JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("metadata/scraper_categories.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("scraper_categories", {})
    except Exception as e:
        print(f"âŒ [LOAD] ìŠ¤í¬ë˜í¼ ì¹´í…Œê³ ë¦¬ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def validate_scrapers(scraper_functions, scraper_types, scraper_categories):
    """
    ìŠ¤í¬ë˜í¼ Lambda í•¨ìˆ˜ë“¤ì´ ìœ íš¨í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤.

    Args:
        scraper_functions: Lambda í•¨ìˆ˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        scraper_types: ìŠ¤í¬ë˜í¼ íƒ€ì… ì •ë³´
        scraper_categories: ìŠ¤í¬ë˜í¼ ì¹´í…Œê³ ë¦¬ ì •ë³´

    Returns:
        List[str]: ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ Lambda í•¨ìˆ˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    """
    valid_scrapers = []

    # JSONì— ì •ì˜ëœ ìŠ¤í¬ë˜í¼ íƒ€ì…ë“¤ì„ ìˆœíšŒí•˜ë©´ì„œ í•´ë‹¹í•˜ëŠ” Lambda í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    for scraper_type, scraper_info in scraper_types.items():
        # 1. ìŠ¤í¬ë˜í¼ íƒ€ì…ì´ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ”ì§€ í™•ì¸
        category = find_category_by_scraper_type(scraper_type, scraper_categories)
        if not category:
            print(
                f"âŒ [VALIDATE] ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ìŠ¤í¬ë˜í¼ íƒ€ì…: {scraper_type}"
            )
            continue

        # 3. JSONì˜ scraper_lambda_function_nameê³¼ ì‹¤ì œ Lambda í•¨ìˆ˜ëª…ì„ ì§ì ‘ ë¹„êµ
        expected_function_name = scraper_info.get("scraper_lambda_function_name")
        if not expected_function_name:
            print(
                f"âŒ [VALIDATE] Lambda í•¨ìˆ˜ëª…ì´ ì •ì˜ë˜ì§€ ì•Šì€ ìŠ¤í¬ë˜í¼ íƒ€ì…: {scraper_type}"
            )
            continue

        # ì‹¤ì œ Lambda í•¨ìˆ˜ ì´ë¦„ ìƒì„± (í™˜ê²½ë³„ ì ‘ë‘ì‚¬ í¬í•¨)
        actual_function_names = generate_actual_function_names(expected_function_name)

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” Lambda í•¨ìˆ˜ ì°¾ê¸°
        matching_function = None
        for actual_name in actual_function_names:
            if actual_name in scraper_functions:
                matching_function = actual_name
                break

        if not matching_function:
            print(
                f"âŒ [VALIDATE] Lambda í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤í¬ë˜í¼ íƒ€ì…: {scraper_type} (ì˜ˆìƒ: {expected_function_name})"
            )
            continue

        print(
            f"âœ… [VALIDATE] ìœ íš¨í•œ ìŠ¤í¬ë˜í¼: {matching_function} ({scraper_type} -> {category})"
        )
        valid_scrapers.append(matching_function)

    return valid_scrapers


def generate_actual_function_names(expected_function_name):
    """
    ì˜ˆìƒë˜ëŠ” Lambda í•¨ìˆ˜ëª…ìœ¼ë¡œë¶€í„° ì‹¤ì œ Lambda í•¨ìˆ˜ëª…ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        expected_function_name: ì˜ˆìƒë˜ëŠ” í•¨ìˆ˜ëª… (ì˜ˆ: university_academic_scraper)

    Returns:
        List[str]: ì‹¤ì œ Lambda í•¨ìˆ˜ëª… ë¦¬ìŠ¤íŠ¸
    """
    # prefix ì—†ì´ ì§ì ‘ ë¹„êµí•˜ë¯€ë¡œ ì˜ˆìƒ í•¨ìˆ˜ëª… ê·¸ëŒ€ë¡œ ë°˜í™˜
    return [expected_function_name]


def find_category_by_scraper_type(scraper_type, scraper_categories):
    """
    ìŠ¤í¬ë˜í¼ íƒ€ì…ì´ ì†í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        scraper_type: ìŠ¤í¬ë˜í¼ íƒ€ì…
        scraper_categories: ìŠ¤í¬ë˜í¼ ì¹´í…Œê³ ë¦¬ ì •ë³´

    Returns:
        str: ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë˜ëŠ” None
    """
    for category_name, category_info in scraper_categories.items():
        if scraper_type in category_info.get("scraper_types", []):
            return category_name
    return None


def get_database(db_name: str = None):
    """MongoDB ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        mongodb_uri = os.environ.get("MONGODB_URI")
        if not mongodb_uri:
            print("âŒ [DB] MongoDB URIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None

        client = MongoClient(mongodb_uri)
        default_db = "dev-kookmin-feed"
        db_name = db_name or os.environ.get("DB_NAME") or default_db
        return client[db_name]
    except Exception as e:
        print(f"âŒ [DB] DB ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def get_collection(db_name: str = None, collection_name: str = None):
    """DBë‚´ ì»¬ë ‰ì…˜ ë°˜í™˜."""
    db = get_database(db_name)
    if db is None:
        return None
    return db[collection_name]


def save_scraper_categories_to_db(scraper_categories):
    """ScraperCategory ë°ì´í„°ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        collection = get_collection(
            db_name="scraper-metadata", collection_name="scraper-categories"
        )
        if collection is None:
            print("âŒ [DB] ì»¬ë ‰ì…˜ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        for category_name, category_info in scraper_categories.items():
            collection.update_one(
                {"name": category_name},
                {
                    "$set": {
                        "korean_name": category_info.get("korean_name", ""),
                        "scraper_type_names": category_info.get("scraper_types", []),
                    }
                },
                upsert=True,
            )
        print("âœ… [DB] ScraperCategory ì €ì¥ ë˜ëŠ” ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"âŒ [DB] ScraperCategory ì €ì¥ ë˜ëŠ” ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def save_scraper_types_to_db(scraper_types, valid_scrapers):
    """ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ íƒ€ì…ë“¤ì„ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        collection = get_collection(
            db_name="scraper-metadata", collection_name="scraper-types"
        )
        if collection is None:
            print("âŒ [DB] ì»¬ë ‰ì…˜ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        saved_count = 0
        for scraper_type, scraper_info in scraper_types.items():
            # ìœ íš¨í•œ ìŠ¤í¬ë˜í¼ë§Œ ì €ì¥
            if scraper_info.get("scraper_lambda_function_name") in valid_scrapers:
                collection.update_one(
                    {"collection_name": scraper_type},
                    {
                        "$set": {
                            "type_name": scraper_type,
                            "korean_name": scraper_info.get("korean_name", ""),
                            "url": scraper_info.get("url", ""),
                            "scraper_class_name": scraper_info.get(
                                "scraper_class_name", ""
                            ),
                            "scraper_lambda_function_name": scraper_info.get(
                                "scraper_lambda_function_name", ""
                            ),
                        }
                    },
                    upsert=True,
                )
                saved_count += 1
                print(
                    f"âœ… [DB] ScraperType ì €ì¥: {scraper_info.get('korean_name', '')}"
                )

        print(f"âœ… [DB] ScraperType ì €ì¥ ë˜ëŠ” ì—…ë°ì´íŠ¸ ì™„ë£Œ: {saved_count}ê°œ")
        return True
    except Exception as e:
        print(f"âŒ [DB] ScraperType ì €ì¥ ë˜ëŠ” ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
